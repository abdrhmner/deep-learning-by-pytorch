{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226c5b5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bbc6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.makedirs (\"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "925053cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test1/test_1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test1/test_1.py\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "num_workers=os.cpu_count()\n",
    "\n",
    "def create_dataloaders (\n",
    "                            train_dir:str,\n",
    "                            test_dir:str,\n",
    "                                transform:transforms.Compose,\n",
    "                                batch_size:int,\n",
    "                                num_workers:int=num_workers):\n",
    "    # Use ImageFolder to create datasets\n",
    "    train_data=datasets.ImageFolder(train_dir, transform=transform)\n",
    "    test_data=datasets.ImageFolder(test_dir,transform=transform)\n",
    "    #Get class names \n",
    "    class_names=train_data.classes\n",
    "    # Turn datasets into dataloaders\n",
    "    train_dataloader=DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers,pin_memory=True    )\n",
    "    test_dataloader=DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "return train_dataloader, test_dataloader, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "263a5e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test1/model_builder.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test1/model_builder.py\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "  \"\"\"Creates the TinyVGG architecture.\n",
    "\n",
    "  Replicates the TinyVGG architecture from the CNN explainer website in PyTorch.\n",
    "  See the original architecture here: https://poloclub.github.io/cnn-explainer/\n",
    "  \n",
    "  Args:\n",
    "    input_shape: An integer indicating number of input channels.\n",
    "    hidden_units: An integer indicating number of hidden units between layers.\n",
    "    output_shape: An integer indicating number of output units.\n",
    "  \"\"\"\n",
    "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "      super().__init__()\n",
    "      self.conv_block_1 = nn.Sequential(\n",
    "          nn.Conv2d(in_channels=input_shape, \n",
    "                    out_channels=hidden_units, \n",
    "                    kernel_size=3, # how big is the square that's going over the image?\n",
    "                    stride=1, # default\n",
    "                    padding=0), # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(in_channels=hidden_units, \n",
    "                    out_channels=hidden_units,\n",
    "                    kernel_size=3,\n",
    "                    stride=1,\n",
    "                    padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(kernel_size=2,\n",
    "                        stride=2) # default stride value is same as kernel_size\n",
    "      )\n",
    "      self.conv_block_2 = nn.Sequential(\n",
    "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=0),\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2)\n",
    "      )\n",
    "      self.classifier = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          # Where did this in_features shape come from? \n",
    "          # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "          nn.Linear(in_features=hidden_units*13*13,\n",
    "                    out_features=output_shape)\n",
    "      )\n",
    "    \n",
    "  def forward(self, x: torch.Tensor):\n",
    "      x = self.conv_block_1(x)\n",
    "      x = self.conv_block_2(x)\n",
    "      x = self.classifier(x)\n",
    "      return x\n",
    "      # return self.classifier(self.block_2(self.block_1(x))) # <- leverage the benefits of operator fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24f4e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test1 import model_builder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
