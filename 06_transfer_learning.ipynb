{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3100d16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "0.24.1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "print (torch.__version__)\n",
    "print (torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69bb4005",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 1] Operation not permitted: 'pytorch-deep-learning/.git/objects/pack/pack-a74a8c228cbf1f469f43bcde8ba08dbed73cd4c3.pack'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:679\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_fd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopfd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: 'pack-a74a8c228cbf1f469f43bcde8ba08dbed73cd4c3.pack'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     os\u001b[38;5;241m.\u001b[39mchmod(path, stat\u001b[38;5;241m.\u001b[39mS_IWRITE)\n\u001b[1;32m      7\u001b[0m     func(path)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpytorch-deep-learning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_readonly\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:725\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    724\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(fd)):\n\u001b[0;32m--> 725\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    727\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(fd)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:658\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(dirfd)):\n\u001b[0;32m--> 658\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(dirfd)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:658\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(dirfd)):\n\u001b[0;32m--> 658\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(dirfd)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:658\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msamestat(orig_st, os\u001b[38;5;241m.\u001b[39mfstat(dirfd)):\n\u001b[0;32m--> 658\u001b[0m         \u001b[43m_rmtree_safe_fd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirfd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monerror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m             os\u001b[38;5;241m.\u001b[39mclose(dirfd)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/shutil.py:681\u001b[0m, in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    679\u001b[0m     os\u001b[38;5;241m.\u001b[39munlink(entry\u001b[38;5;241m.\u001b[39mname, dir_fd\u001b[38;5;241m=\u001b[39mtopfd)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m--> 681\u001b[0m     \u001b[43monerror\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munlink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfullname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m, in \u001b[0;36mremove_readonly\u001b[0;34m(func, path, _)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mremove_readonly\u001b[39m(func, path, _):\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mS_IWRITE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     func(path)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 1] Operation not permitted: 'pytorch-deep-learning/.git/objects/pack/pack-a74a8c228cbf1f469f43bcde8ba08dbed73cd4c3.pack'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import stat\n",
    "import shutil\n",
    "\n",
    "def remove_readonly(func, path, _):\n",
    "    os.chmod(path, stat.S_IWRITE)\n",
    "    func(path)\n",
    "\n",
    "shutil.rmtree(\"pytorch-deep-learning\", onerror=remove_readonly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fefb51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading going_modular scripts...\n",
      "fatal: destination path 'pytorch-deep-learning' already exists and is not an empty directory.\n",
      "Error: [Errno 2] No such file or directory: 'pytorch-deep-learning/going_modular'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from torchvision import models\n",
    "\n",
    "# Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ going_modular Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯\n",
    "if os.path.exists(\"going_modular\"):\n",
    "    shutil.rmtree(\"going_modular\")\n",
    "\n",
    "try:\n",
    "    print(\"Downloading going_modular scripts...\")\n",
    "    \n",
    "    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø±ÙŠØ¨Ùˆ Ø¨Ø¹Ù…Ù‚ Ù…Ù†Ø®ÙØ¶ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ­Ù…ÙŠÙ„\n",
    "    !git clone --depth 1 https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    \n",
    "    # Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯\n",
    "    shutil.move(\"pytorch-deep-learning/going_modular\", \".\")\n",
    "    \n",
    "    # Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø±ÙŠØ¨Ùˆ\n",
    "    shutil.rmtree(\"pytorch-deep-learning\")\n",
    "    \n",
    "    print(\"Done!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce489ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ZIP...\n",
      "Extracting ZIP...\n"
     ]
    },
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 3) ÙÙƒ Ø§Ù„Ø¶ØºØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Python\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting ZIP...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m     22\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 4) Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµØ­ÙŠØ­\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/zipfile.py:1267\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1267\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1269\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/zipfile.py:1334\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1336\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "# 1) Ø­Ø°Ù Ù…Ø¬Ù„Ø¯ going_modular Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯\n",
    "if os.path.exists(\"going_modular\"):\n",
    "    shutil.rmtree(\"going_modular\")\n",
    "\n",
    "# 2) ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ZIP Ù…Ù† Ø§Ù„ÙØ±Ø¹ Ø§Ù„ØµØ­ÙŠØ­\n",
    "url = \"https://github.com/mrdbourke/pytorch-deep-learning/archive/refs/heads/04-going-modular.zip\"\n",
    "zip_path = \"gmod.zip\"\n",
    "\n",
    "print(\"Downloading ZIP...\")\n",
    "r = requests.get(url)\n",
    "with open(zip_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "# 3) ÙÙƒ Ø§Ù„Ø¶ØºØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Python\n",
    "print(\"Extracting ZIP...\")\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "\n",
    "# 4) Ù†Ù‚Ù„ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„ØµØ­ÙŠØ­\n",
    "src = \"pytorch-deep-learning-04-going-modular/going_modular\"\n",
    "dst = \"going_modular\"\n",
    "\n",
    "print(\"Moving going_modular directory...\")\n",
    "shutil.move(src, dst)\n",
    "\n",
    "# 5) ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª\n",
    "shutil.rmtree(\"pytorch-deep-learning-04-going-modular\")\n",
    "os.remove(zip_path)\n",
    "\n",
    "print(\"Done! going_modular is ready.\")\n",
    "\n",
    "# 6) Ø§Ù„Ø¢Ù† Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø³ÙŠØ¹Ù…Ù„\n",
    "from going_modular import data_setup, engine\n",
    "print(\"Import successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415d724",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'data_setup' from 'going_modular' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoing_modular\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_setup, engine\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'data_setup' from 'going_modular' (unknown location)"
     ]
    }
   ],
   "source": [
    "from going_modular import data_setup, engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773ba44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¨Ù…Ø³Ø§Ø± ØµØ­ÙŠØ­\n",
    "    from going_modular import data_setup, engine\n",
    "except ImportError:\n",
    "    print(\"Downloading scripts...\")\n",
    "    # ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹ Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹\n",
    "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
    "    !mv pytorch-deep-learning/going_modular .\n",
    "    !rm -rf pytorch-deep-learning\n",
    "    \n",
    "    # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø²ÙŠÙ„\n",
    "    from going_modular import data_setup, engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "data_path=Path(\"data/\")\n",
    "image_path=data_path/\"pizza_steak_sushi\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46fc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "# setup directories\n",
    "train_dir=image_path/\"train\"\n",
    "test_dir=image_path/\"test\"\n",
    "\n",
    "# print out the class names\n",
    "class_names=os.listdir(train_dir)\n",
    "print (class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9e6d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'data_setup' from 'going_modular' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoing_modular\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_setup, engine\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transforms\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'data_setup' from 'going_modular' (unknown location)"
     ]
    }
   ],
   "source": [
    "from going_modular import data_setup, engine\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "\n",
    "normalize=transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "manual_transforms=transforms.Compose([\n",
    "    transforms.Resize((224,224)),transforms.ToTensor(),normalize\n",
    "])\n",
    "\n",
    "# Create DataLoaders\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32ea35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader,test_dataloader,class_names=data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                            test_dir=test_dir,transform=manual_transforms,\n",
    "                                                            batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101c10f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m weights\u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mEfficientNet_B0_Weights\u001b[38;5;241m.\u001b[39mDEFAULT\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mefficientnet_b0(weights\u001b[38;5;241m=\u001b[39mweights)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "weights= torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model=models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69339c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_transforms=weights.transforms()\n",
    "auto_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9db68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x261808db4f0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x261808d8eb0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader,test_dataloader, class_names =data_setup.create_dataloaders(train_dir=train_dir,\n",
    "                                                            test_dir=test_dir,transform=auto_transforms,batch_size=32)  \n",
    "train_dataloader,test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdb621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n",
      "training...\n",
      "epoch: 1,   loss: 36991.9832\n",
      "epoch: 2,   loss: 4553.0580\n",
      "epoch: 3,   loss: 4849.5584\n",
      "epoch: 4,   loss: 3596.7735\n",
      "epoch: 5,   loss: 2391.2503\n",
      "runtime: 19.28 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "\n",
    "## math function to approximate :\n",
    "# f(x) = sum over i of x_i * sin(x_i) + 0.5 * sum over i of x_i^2\n",
    "\n",
    "\n",
    "#device = torch.device(\"cpu\")\n",
    "device = torch.device(\"mps\")\n",
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "\n",
    "num_samples = 50000\n",
    "input_dim = 1000\n",
    "hidden_dim = 4096\n",
    "output_dim = 1 \n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "# f(x) = sum over i of x_i * sin(x_i) + 0.5 * sum over i of x_i^2\n",
    "X_train = np.random.randn(num_samples, input_dim)\n",
    "y_train = np.sum(X_train * np.sin(X_train), axis=1) + 0.5 * np.sum(X_train**2, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "print(\"training...\")\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    perm = torch.randperm(X_train.size(0))\n",
    "    X_train = X_train[perm]\n",
    "    y_train = y_train[perm]\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    net.train()\n",
    "    for i in range(0, X_train.size(0), batch_size):\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    avg_loss = epoch_loss / (X_train.size(0) / batch_size)\n",
    "    print(f\"epoch: {epoch+1},   loss: {avg_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"runtime: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78440c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Using Apple M4 Pro (MPS)\n",
      "Generating Data...\n",
      "Training started...\n",
      "Final Runtime on M4 Pro: 4.8820 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙØ¹ÙŠÙ„ MPS\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"ðŸš€ Using Apple M4 Pro (MPS)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# --- Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ Ù„Ù„Ø³Ø±Ø¹Ø© ---\n",
    "# Ø§Ù„Ù€ M4 Pro ÙŠØ­Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø©. \n",
    "# Ø±ÙØ¹Ù†Ø§ Ø§Ù„Ø±Ù‚Ù… Ù„ØªÙ‚Ù„ÙŠÙ„ Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„ÙƒØ±Øª\n",
    "batch_size = 10000 \n",
    "num_samples = 50000\n",
    "input_dim = 1000\n",
    "hidden_dim = 4096\n",
    "output_dim = 1 \n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "print(\"Generating Data...\")\n",
    "X_train_np = np.random.randn(num_samples, input_dim).astype(np.float32)\n",
    "y_train_np = np.sum(X_train_np * np.sin(X_train_np), axis=1) + 0.5 * np.sum(X_train_np**2, axis=1)\n",
    "\n",
    "# Ù†Ù‚Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù€ MPS\n",
    "X_train = torch.from_numpy(X_train_np).to(device)\n",
    "y_train = torch.from_numpy(y_train_np).view(-1, 1).to(device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # nn.Sequential Ø£Ø³Ø±Ø¹ Ù‚Ù„ÙŠÙ„Ø§Ù‹ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "net = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "# Warmup: ØªØ´ØºÙŠÙ„Ø© ÙˆÙ‡Ù…ÙŠØ© Ù„ØªØ³Ø®ÙŠÙ† Ø§Ù„ÙƒØ§Ø´ Ø§Ù„Ø®Ø§Øµ Ø¨Ù€ Metal\n",
    "net(X_train[:batch_size])\n",
    "torch.mps.synchronize() # Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…Ø§Ùƒ\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Ø®Ù„Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª\n",
    "    perm = torch.randperm(num_samples, device=device)\n",
    "    X_train = X_train[perm]\n",
    "    y_train = y_train[perm]\n",
    "\n",
    "    net.train()\n",
    "    \n",
    "    # Ø§Ù„Ù€ Loop Ø£ØµØ¨Ø­ Ø£Ù‚ØµØ± Ø¨ÙƒØ«ÙŠØ± (5 Ø®Ø·ÙˆØ§Øª ÙÙ‚Ø· Ù„ÙƒÙ„ Epoch Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 390)\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        # ØªØ­Ø¯ÙŠØ¯ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù€ Batch\n",
    "        end_idx = min(i + batch_size, num_samples)\n",
    "        \n",
    "        batch_X = X_train[i:end_idx]\n",
    "        batch_y = y_train[i:end_idx]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Ù…Ø²Ø§Ù…Ù†Ø© Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø£Ù† Ø§Ù„Ù…Ø§Ùƒ Ø£Ù†Ù‡Ù‰ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª\n",
    "torch.mps.synchronize()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Final Runtime on M4 Pro: {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b22e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ M4 Pro: Engaging Max Velocity (Float16 + Full Batch)\n",
      "Generating Data...\n",
      "Training started...\n",
      "Final Runtime on M4 Pro (FP16): 0.5489 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(\"ðŸš€ M4 Pro: Engaging Max Velocity (Float16 + Full Batch)\")\n",
    "\n",
    "# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª\n",
    "num_samples = 50000\n",
    "input_dim = 1000\n",
    "hidden_dim = 1024\n",
    "output_dim = 1 \n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "print(\"Generating Data...\")\n",
    "X_train_np = np.random.randn(num_samples, input_dim).astype(np.float16) # Ø§Ø³ØªØ®Ø¯Ø§Ù… float16\n",
    "y_train_np = np.sum(X_train_np.astype(np.float32) * np.sin(X_train_np.astype(np.float32)), axis=1) + 0.5 * np.sum(X_train_np.astype(np.float32)**2, axis=1)\n",
    "\n",
    "# Ø§Ù„Ù†Ù‚Ù„ Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø¨ØµÙŠØºØ© Float16\n",
    "X_train = torch.from_numpy(X_train_np).to(device) # float16 ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù€ numpy\n",
    "y_train = torch.from_numpy(y_train_np.astype(np.float16)).view(-1, 1).to(device)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "# Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙŠØ¶Ø§Ù‹ Ø¨ØµÙŠØºØ© float16\n",
    "net = Net().to(device).half() \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "# Warmup\n",
    "net(X_train[:100])\n",
    "torch.mps.synchronize()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ÙÙŠ Full Batch Gradient DescentØŒ Ù„Ø§ Ù†Ø­ØªØ§Ø¬ Ù„Ø®Ù„Ø· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙƒÙ„ Ù…Ø±Ø©\n",
    "    # Ù„Ø£Ù†Ù†Ø§ Ù†Ø£Ø®Ø° Ø§Ù„Ù…ØªÙˆØ³Ø· Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„ Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ù„ÙƒÙ„ (Ø£Ù‚ØµÙ‰ Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ±Øª ÙˆØ£Ù‚Ù„ ÙˆÙ‚Øª Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬)\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "torch.mps.synchronize()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Final Runtime on M4 Pro (FP16): {end_time - start_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a999462",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchvision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m weights\u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mEfficientNet_B0_Weights\u001b[38;5;241m.\u001b[39mDEFAULT\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mefficientnet_b0(weights\u001b[38;5;241m=\u001b[39mweights)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
     ]
    }
   ],
   "source": [
    "weights= torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "model=torchvision.models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599143d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2dNormActivation(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SiLU(inplace=True)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "    )\n",
       "    (1): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "    )\n",
       "    (2): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "    )\n",
       "    (3): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "          (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): SiLU(inplace=True)\n",
       "          (scale_activation): Sigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "    )\n",
       "  )\n",
       "  (8): Conv2dNormActivation(\n",
       "    (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): SiLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features.parameters():\n",
    "    #print (param)\n",
    "    param.requires_grad=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c683bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1280, out_features=3, bias=True)\n",
       "  (1): Dropout(p=0.2, inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier=nn.Sequential(nn.Linear(in_features=1280, out_features=len(class_names))\n",
    "                                , nn.Dropout(p=0.2, inplace=True)).to(device)\n",
    "model.classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
